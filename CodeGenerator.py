import json
import os
import logging
from typing import Dict, List, Any, Optional, Union
import google.generativeai as genai #type: ignore

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('DataSynthesizer')

class CodeGenerator:
    """
    Component responsible for generating Python code for data synthesis
    using LLM (Gemini 2.5 Pro Preview).
    """

    def __init__(self, api_key: str):
        """
        Initialize the Code Generator component.

        Args:
            api_key: Google API key for accessing Gemini model
        """
        self.api_key = api_key

        # Configure the Gemini API
        genai.configure(api_key=api_key)

        self.model = genai.GenerativeModel(
            #model_name="models/gemini-2.5-pro-preview-05-06"
            model_name="models/gemini-2.5-flash-preview-04-17"
        )

        logger.info(f"Code Generator initialized with {self.model.model_name}")

    def _load_requirements(self, requirements_path: str) -> str:
        """
        Load the requirements document generated by the LLM Analyzer.
        """
        logger.info(f"Loading requirements from {requirements_path}")
        try:
            with open(requirements_path, 'r', encoding='utf-8') as f:
                requirements = f.read()
            logger.info("Successfully loaded requirements document")
            return requirements
        except Exception as e:
            logger.error(f"Error loading requirements: {str(e)}")
            raise

    def _load_ordered_columns(self, ordered_columns_path: str) -> List[Dict[str, Any]]:
        """
        Load the ordered columns JSON file generated by the LLM Analyzer.
        """
        logger.info(f"Loading ordered columns from {ordered_columns_path}")
        try:
            with open(ordered_columns_path, 'r', encoding='utf-8') as f:
                ordered_columns = json.load(f)
            logger.info(f"Successfully loaded {len(ordered_columns)} ordered columns")
            return ordered_columns
        except Exception as e:
            logger.error(f"Error loading ordered columns: {str(e)}")
            raise

    def _gather_feedback(self, feedback: Optional[Dict[str, Any]]) -> str:
        """
        Compiles feedback from code review and execution/validation failures.
        """
        feedback_parts = []
        feedback_parts.append("The previous attempt to generate and run the data synthesis code had issues.")

        if feedback and not feedback.get("pass", True) :
            feedback_parts.append("\n--- Code Review Feedback ---")
            if feedback.get("summary"):
                feedback_parts.append(f"Review Summary: {feedback['summary']}")

            critical_issues = feedback.get("critical_issues", [])
            if critical_issues:
                feedback_parts.append("Critical Issues Found:")
                for issue in critical_issues:
                    feedback_parts.append(
                        f"- Type: {issue.get('type', 'N/A')}\n"
                        f"  Description: {issue.get('description', 'N/A')}\n"
                        f"  Location: {issue.get('location', 'N/A')}\n"
                        f"  Recommendation: {issue.get('recommendation', 'N/A')}"
                    )

            non_critical_issues = feedback.get("non_critical_issues", [])
            if non_critical_issues:
                feedback_parts.append("Non-Critical Issues/Suggestions:")
                for issue in non_critical_issues:
                     feedback_parts.append(
                        f"- Type: {issue.get('type', 'N/A')}\n"
                        f"  Description: {issue.get('description', 'N/A')}\n"
                        f"  Location: {issue.get('location', 'N/A')}\n"
                        f"  Recommendation: {issue.get('recommendation', 'N/A')}"
                    )

        if feedback and not feedback.get("overall_success", True):
            feedback_parts.append("\n--- Code Execution/Validation Feedback ---")
            if feedback.get("summary"):
                 feedback_parts.append(f"Execution/Validation Summary: {feedback['summary']}")

            exec_details = feedback.get("execution", {})
            if not exec_details.get("success", True):
                feedback_parts.append("Execution Failed:")
                if exec_details.get("error"):
                    feedback_parts.append(f"  Error: {exec_details['error']}")
                if exec_details.get("traceback"):
                    feedback_parts.append(f"  Traceback:\n{exec_details['traceback']}")

            val_details = feedback.get("validation", {})
            if not val_details.get("success", True):
                feedback_parts.append("Data Validation Failed:")
                if val_details.get("summary"):
                     feedback_parts.append(f"  Validation Summary: {val_details['summary']}")
                failed_checks = [v for v in val_details.get("validations", []) if not v.get("passed")]
                if failed_checks:
                    feedback_parts.append("  Specific Validation Failures:")
                    for check in failed_checks[:5]: # Limit to first 5 for brevity
                        feedback_parts.append(
                            f"  - Check: {check.get('name', 'N/A')}\n"
                            f"    Description: {check.get('description', 'N/A')}\n"
                            f"    Details: {check.get('details', 'N/A')}"
                        )

        feedback_parts.append("\nPlease analyze this feedback and regenerate the Python script to address these issues. "
                              "Ensure the new script adheres to all original requirements and fixes the reported problems.")

        return "\n".join(feedback_parts)

    def _load_search_results(self, search_results_path: str) -> Dict[str, Any]:
        """
        Load the search results JSON file generated by the Web Search Agent.
        """
        logger.info(f"Loading search results from {search_results_path}")
        try:
            if not os.path.exists(search_results_path):
                logger.warning(f"Search results file not found at {search_results_path}")
                return {}

            with open(search_results_path, 'r', encoding='utf-8') as f:
                search_results = json.load(f)
            logger.info("Successfully loaded search results")
            return search_results
        except Exception as e:
            logger.error(f"Error loading search results: {str(e)}")
            return {}

    def get_critical_issues_summary(self, review_results: Dict[str, Any]) -> str:
        """
        Generate a summary of critical issues from the code review results.
        """
        if not review_results.get("critical_issues"):
            return "No critical issues found."

        summary = "Critical issues found:\n\n"
        for i, issue in enumerate(review_results["critical_issues"], 1):
            summary += f"{i}. {issue.get('type', 'Unknown')} issue: {issue.get('description', 'No description')}\n"
            summary += f"   Location: {issue.get('location', 'Unknown')}\n"
            summary += f"   Recommendation: {issue.get('recommendation', 'No recommendation')}\n\n"

        return summary

    def _construct_code_generation_prompt(self,
                                        requirements: str,
                                        ordered_columns: List[Dict[str, Any]],
                                        search_results: Dict[str, Any],
                                        output_format: str = "csv",
                                        num_rows: int = 1000,
                                        feedback: Optional[str] = None,
                                        previous_code: Optional[str] = None, # Added previous_code
                                        original_column_order: Optional[List[str]] = None,
                                        frozen_columns: Optional[List[str]] = None) -> str:
        """
        Construct a detailed prompt for the LLM to generate synthetic data generation code.
        Includes previous code as reference if provided.
        """
        logger.info("Constructing code generation prompt")
        print(f"feedback: {feedback}")
        print(f"frozen: {frozen_columns}")

        search_results_section = "### Search Results Information:\n\n"
        search_results_data = search_results.get("results", {}) 

        for column_name, result in search_results_data.items():
            if isinstance(result, dict) and result.get("search_required", False) and "content" in result:
                search_results_section += f"#### Search Results for {column_name}:\n\n"
                for content_entry in result["content"][:3]:
                    code_examples = content_entry.get("code_examples", [])
                    if code_examples:
                        search_results_section += "Code Examples:\n"
                        for example in code_examples:  
                            search_results_section += f"```python\n{example}\n```\n\n"

                    text_snippet = content_entry.get("text_content", "").strip()
                    if text_snippet:
                        search_results_section += "Additional Context:\n"
                        search_results_section += f"{text_snippet[:1000]}\n\n"

        frozen_section = ""
        if frozen_columns:
            frozen_section = f"""After code review, These are the columns that passed (creation-wise, not order-wise), Do not modify logic for the following validated columns: {', '.join(frozen_columns)}."""

        feedback_section = ""
        if feedback:
            feedback_section = f"""
# IMPORTANT: Previous Attempt Feedback
The previous attempt to generate code resulted in errors or did not meet requirements.
Please carefully review the following feedback and modify the code to address these issues:

{feedback}

Ensure your new script fixes these problems while still adhering to all original requirements.
"""
        previous_code_section = ""
        if previous_code and feedback: 
             previous_code_section = f"""
# Previous Code (for reference)
This is the code generated in the previous attempt that resulted in the feedback above.
Please use this as a reference to understand the existing structure and logic, and generate a new, corrected version.

```python
{previous_code}
```
"""
        original_order_section = ""
        if original_column_order:
            original_order_section = f"""
# Original Sample Data Column Order
It is CRITICAL that the final output data (e.g., the CSV file) has columns in the following exact order:

```
{', '.join(original_column_order)}
```

After you generate columns internally in a different order based on dependencies,
the final output file MUST arrange the columns in this specified order.
"""

        # Construct the full prompt
        prompt = f"""
You are an expert Python developer specializing in data generation and synthesis. Your task is to create a complete,
standalone Python script that generates realistic synthetic data according to the requirements specified below.

{feedback_section}
{frozen_section}
{previous_code_section} 

# Requirements and Specifications
- The script should be completely self-contained, with all necessary imports and functions.
- Leave out all comments
- DO NOT use the faker library; instead use mimesis or custom implementations.
- Follow the exact column generation order priority as specified in the requirements.
- Implement all column relationships and constraints.
- Include concise, proper error handling and logging (to better understand failures in next attempts).

## Output Requirements:
- Format: {output_format}
- Number of rows to generate: {num_rows}
- The output should have realistic data distributions and patterns that match the requirements.
- Save the output to exactly this path pipeline_run_outputs/generated_data_script.py

{original_order_section}

## Column Generation Order and Details:
The columns must be generated in the specific priority order detailed in the requirements document.

{requirements}

Use the following search results to use the correct and most up-to-date information on ultilizing libraries:
{search_results_section}

# Code Generation Instructions

1. Start with necessary imports and setup:
   - Import all required libraries (mimesis Version: 18.0.0, random, etc.)
   - Set up logging
   - Define constants (output file paths, number of rows, etc.)

2. Create appropriate data generation functions for each column:
   - For columns using standard providers, use the appropriate mimesis providers
   - For columns requiring custom patterns, implement custom generation logic
   - For columns with relationships, ensure proper dependencies are maintained
   - Include appropriate error handling

3. Implement the main data generation process:
   - Generate data in the specified column order
   - Respect all constraints and relationships
   - Store the generated data appropriately
   - Rearrange the columns in the final output to match the original order

4. Add code to write the output to the specified format
   - Include proper file handling
   - Format the output correctly

5. Include a main function that orchestrates the entire process

Remember:
- Your code should be production-ready and well-structured
- Include type hints where appropriate
- Handle edge cases and potential errors gracefully
- Focus on generating realistic data that meets all the requirements

Generate the complete Python script that fulfills these requirements. The script should be ready to run without
any modifications.
"""
        return prompt

    def generate_code(
        self,
        requirements_path: str,
        ordered_columns_path: str,
        search_results_path: str,
        output_format: str,
        num_rows: int,
        feedback: Optional[str],
        previous_code: Optional[str],
        original_column_order: Optional[List[str]],
        frozen_columns: Optional[List[str]] = None
    ) -> str:
        """
        Generate Python code using structured prompt logic and provided paths.
        """
        try:
            with open(requirements_path, 'r', encoding='utf-8') as f:
                requirements = f.read()
        except Exception:
            requirements = ""

        try:
            with open(ordered_columns_path, 'r', encoding='utf-8') as f:
                ordered_columns = json.load(f)
        except Exception:
            ordered_columns = []

        try:
            with open(search_results_path, 'r', encoding='utf-8') as f:
                search_results = json.load(f)
        except Exception:
            search_results = {}

        prompt = self._construct_code_generation_prompt(
            requirements,
            ordered_columns,
            search_results,
            output_format,
            num_rows,
            feedback,
            previous_code,
            original_column_order,
            frozen_columns
            )

        try:
            logger.info("Sending code generation prompt to LLM")
            response = self.model.generate_content(prompt)
            code = self._extract_code_from_response(response.text)
            return code
        except Exception as e:
            logger.error(f"Code generation failed: {str(e)}")
            return ""

    def _extract_code_from_response(self, response_text: str) -> str:
        """
        Extract Python code from the LLM response text.
        """
        try:
            # Look for Python code blocks (```python...```)
            code_start = response_text.find("```python")
            if code_start >= 0:
                code_start += len("```python")
                code_end = response_text.find("```", code_start)
                if code_end >= 0:
                    return response_text[code_start:code_end].strip()

            # If no Python-specific code block, look for general code blocks
            code_start = response_text.find("```")
            if code_start >= 0:
                code_start += len("```")
                code_end = response_text.find("```", code_start)
                if code_end >= 0:
                    return response_text[code_start:code_end].strip()

            # If no code blocks found, return the full response as it might be just code
            logger.warning("No code block markers found in response, returning full text")
            return response_text.strip()

        except Exception as e:
            logger.error(f"Error extracting code from response: {str(e)}")
            logger.debug(f"Response text: {response_text[:500]}...")  # Log first 500 chars for debugging
            return response_text.strip()

    def save_generated_code(self, code: str, output_path: str = "pipeline_run_outputs/generated_data_script.py") -> str:
        """
        Save the generated code to a file.
        """
        logger.info(f"Saving generated code to {output_path}")

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(code)
            logger.info(f"Code successfully saved to {output_path}")
            return output_path
        except Exception as e:
            logger.error(f"Error saving generated code: {str(e)}")
            raise

if __name__ == "__main__":
    api_key = os.getenv("GOOGLE_API_KEY")

    if not api_key:
        logger.error("No Google API key found in environment variables")
        exit(1)

    generator = CodeGenerator(api_key)

    code = generator.generate_code(
        requirements_path="pipeline_run_outputs/generation_requirements.txt",
        ordered_columns_path="pipeline_run_outputs/ordered_columns_for_generation.json",
        search_results_path="pipeline_run_outputs/web_search_results.json",
        output_format="csv",
        num_rows=200,
        feedback=None
        # previous_code is not passed in the first run
    )

    # Save the generated code
    output_path = generator.save_generated_code(code)

    print(f"Code generation complete. Output saved to {output_path}")
